{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Chest X-ray Image Report Generation (CXIRG)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Install Required Modules"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Collecting openpyxl\n",
                        "  Downloading openpyxl-3.1.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
                        "Collecting et-xmlfile (from openpyxl)\n",
                        "  Downloading et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
                        "Downloading openpyxl-3.1.4-py2.py3-none-any.whl (251 kB)\n",
                        "   ---------------------------------------- 0.0/251.4 kB ? eta -:--:--\n",
                        "   - -------------------------------------- 10.2/251.4 kB ? eta -:--:--\n",
                        "   ------ -------------------------------- 41.0/251.4 kB 393.8 kB/s eta 0:00:01\n",
                        "   ----------- --------------------------- 71.7/251.4 kB 491.5 kB/s eta 0:00:01\n",
                        "   --------------------- ---------------- 143.4/251.4 kB 774.0 kB/s eta 0:00:01\n",
                        "   ------------------------------ ------- 204.8/251.4 kB 888.4 kB/s eta 0:00:01\n",
                        "   -------------------------------------- 251.4/251.4 kB 964.5 kB/s eta 0:00:00\n",
                        "Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
                        "Installing collected packages: et-xmlfile, openpyxl\n",
                        "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.4\n",
                        "Requirement already satisfied: pandas in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (2.0.3)\n",
                        "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas) (2.9.0)\n",
                        "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas) (2024.1)\n",
                        "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas) (2023.3)\n",
                        "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas) (1.24.3)\n",
                        "Requirement already satisfied: six>=1.5 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
                        "Requirement already satisfied: pillow in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (10.3.0)\n",
                        "Collecting pytorch-ignite\n",
                        "  Using cached pytorch_ignite-0.5.0.post2-py3-none-any.whl.metadata (27 kB)\n",
                        "Requirement already satisfied: torch<3,>=1.3 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from pytorch-ignite) (2.3.1)\n",
                        "Requirement already satisfied: packaging in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from pytorch-ignite) (24.1)\n",
                        "Requirement already satisfied: filelock in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch<3,>=1.3->pytorch-ignite) (3.13.1)\n",
                        "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch<3,>=1.3->pytorch-ignite) (4.11.0)\n",
                        "Requirement already satisfied: sympy in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch<3,>=1.3->pytorch-ignite) (1.12)\n",
                        "Requirement already satisfied: networkx in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch<3,>=1.3->pytorch-ignite) (3.1)\n",
                        "Requirement already satisfied: jinja2 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch<3,>=1.3->pytorch-ignite) (3.1.4)\n",
                        "Collecting fsspec (from torch<3,>=1.3->pytorch-ignite)\n",
                        "  Downloading fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
                        "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch<3,>=1.3->pytorch-ignite)\n",
                        "  Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
                        "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch<3,>=1.3->pytorch-ignite)\n",
                        "  Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
                        "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch<3,>=1.3->pytorch-ignite)\n",
                        "  Using cached tbb-2021.12.0-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
                        "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from jinja2->torch<3,>=1.3->pytorch-ignite) (2.1.3)\n",
                        "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from sympy->torch<3,>=1.3->pytorch-ignite) (1.3.0)\n",
                        "Using cached pytorch_ignite-0.5.0.post2-py3-none-any.whl (296 kB)\n",
                        "Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
                        "Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
                        "Using cached tbb-2021.12.0-py3-none-win_amd64.whl (286 kB)\n",
                        "Downloading fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
                        "   ---------------------------------------- 0.0/176.9 kB ? eta -:--:--\n",
                        "   -- ------------------------------------- 10.2/176.9 kB ? eta -:--:--\n",
                        "   --------- ----------------------------- 41.0/176.9 kB 393.8 kB/s eta 0:00:01\n",
                        "   --------------- ----------------------- 71.7/176.9 kB 558.5 kB/s eta 0:00:01\n",
                        "   ------------------------------ ------- 143.4/176.9 kB 774.0 kB/s eta 0:00:01\n",
                        "   -------------------------------------- 176.9/176.9 kB 821.1 kB/s eta 0:00:00\n",
                        "Installing collected packages: tbb, intel-openmp, mkl, fsspec, pytorch-ignite\n",
                        "Successfully installed fsspec-2024.6.0 intel-openmp-2021.4.0 mkl-2021.4.0 pytorch-ignite-0.5.0.post2 tbb-2021.12.0\n",
                        "Collecting scikit-learn\n",
                        "  Downloading scikit_learn-1.3.2-cp38-cp38-win_amd64.whl.metadata (11 kB)\n",
                        "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
                        "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
                        "Collecting joblib>=1.1.1 (from scikit-learn)\n",
                        "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
                        "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
                        "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
                        "Downloading scikit_learn-1.3.2-cp38-cp38-win_amd64.whl (9.3 MB)\n",
                        "   ---------------------------------------- 0.0/9.3 MB ? eta -:--:--\n",
                        "   ---------------------------------------- 0.0/9.3 MB 1.3 MB/s eta 0:00:08\n",
                        "   ---------------------------------------- 0.0/9.3 MB 1.3 MB/s eta 0:00:08\n",
                        "   ---------------------------------------- 0.1/9.3 MB 655.4 kB/s eta 0:00:14\n",
                        "    --------------------------------------- 0.1/9.3 MB 717.5 kB/s eta 0:00:13\n",
                        "    --------------------------------------- 0.2/9.3 MB 1.1 MB/s eta 0:00:09\n",
                        "   - -------------------------------------- 0.3/9.3 MB 983.0 kB/s eta 0:00:10\n",
                        "   -- ------------------------------------- 0.5/9.3 MB 1.6 MB/s eta 0:00:06\n",
                        "   -- ------------------------------------- 0.6/9.3 MB 1.6 MB/s eta 0:00:06\n",
                        "   ---- ----------------------------------- 1.0/9.3 MB 2.5 MB/s eta 0:00:04\n",
                        "   ---- ----------------------------------- 1.2/9.3 MB 2.5 MB/s eta 0:00:04\n",
                        "   ------ --------------------------------- 1.5/9.3 MB 3.1 MB/s eta 0:00:03\n",
                        "   ------ --------------------------------- 1.5/9.3 MB 3.1 MB/s eta 0:00:03\n",
                        "   -------- ------------------------------- 2.1/9.3 MB 3.4 MB/s eta 0:00:03\n",
                        "   ----------- ---------------------------- 2.6/9.3 MB 4.1 MB/s eta 0:00:02\n",
                        "   ------------ --------------------------- 2.9/9.3 MB 4.2 MB/s eta 0:00:02\n",
                        "   --------------- ------------------------ 3.5/9.3 MB 4.7 MB/s eta 0:00:02\n",
                        "   --------------- ------------------------ 3.5/9.3 MB 4.7 MB/s eta 0:00:02\n",
                        "   --------------- ------------------------ 3.5/9.3 MB 4.7 MB/s eta 0:00:02\n",
                        "   --------------------- ------------------ 5.0/9.3 MB 5.6 MB/s eta 0:00:01\n",
                        "   ---------------------- ----------------- 5.2/9.3 MB 5.7 MB/s eta 0:00:01\n",
                        "   ---------------------- ----------------- 5.2/9.3 MB 5.7 MB/s eta 0:00:01\n",
                        "   ---------------------- ----------------- 5.2/9.3 MB 5.7 MB/s eta 0:00:01\n",
                        "   ---------------------- ----------------- 5.2/9.3 MB 5.7 MB/s eta 0:00:01\n",
                        "   ---------------------- ----------------- 5.2/9.3 MB 5.7 MB/s eta 0:00:01\n",
                        "   ---------------------- ----------------- 5.2/9.3 MB 5.7 MB/s eta 0:00:01\n",
                        "   ---------------------- ----------------- 5.2/9.3 MB 5.7 MB/s eta 0:00:01\n",
                        "   ---------------------- ----------------- 5.2/9.3 MB 5.7 MB/s eta 0:00:01\n",
                        "   ---------------------- ----------------- 5.2/9.3 MB 5.7 MB/s eta 0:00:01\n",
                        "   ---------------------- ----------------- 5.2/9.3 MB 5.7 MB/s eta 0:00:01\n",
                        "   ---------------------- ----------------- 5.2/9.3 MB 5.7 MB/s eta 0:00:01\n",
                        "   ---------------------- ----------------- 5.2/9.3 MB 5.7 MB/s eta 0:00:01\n",
                        "   ---------------------- ----------------- 5.2/9.3 MB 5.7 MB/s eta 0:00:01\n",
                        "   ---------------------- ----------------- 5.2/9.3 MB 5.7 MB/s eta 0:00:01\n",
                        "   ---------------------- ----------------- 5.2/9.3 MB 5.7 MB/s eta 0:00:01\n",
                        "   ---------------------- ----------------- 5.2/9.3 MB 5.7 MB/s eta 0:00:01\n",
                        "   ----------------------- ---------------- 5.5/9.3 MB 3.3 MB/s eta 0:00:02\n",
                        "   ------------------------- -------------- 6.0/9.3 MB 3.5 MB/s eta 0:00:01\n",
                        "   --------------------------- ------------ 6.3/9.3 MB 3.5 MB/s eta 0:00:01\n",
                        "   ----------------------------- ---------- 6.8/9.3 MB 3.7 MB/s eta 0:00:01\n",
                        "   ------------------------------ --------- 7.1/9.3 MB 3.8 MB/s eta 0:00:01\n",
                        "   ------------------------------ --------- 7.2/9.3 MB 3.8 MB/s eta 0:00:01\n",
                        "   ------------------------------ --------- 7.2/9.3 MB 3.8 MB/s eta 0:00:01\n",
                        "   ----------------------------------- ---- 8.2/9.3 MB 4.1 MB/s eta 0:00:01\n",
                        "   ------------------------------------ --- 8.5/9.3 MB 4.1 MB/s eta 0:00:01\n",
                        "   ------------------------------------- -- 8.8/9.3 MB 4.2 MB/s eta 0:00:01\n",
                        "   ---------------------------------------  9.1/9.3 MB 4.2 MB/s eta 0:00:01\n",
                        "   ---------------------------------------- 9.3/9.3 MB 4.2 MB/s eta 0:00:00\n",
                        "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
                        "   ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
                        "   ------------------------------------ --- 276.5/301.8 kB 5.7 MB/s eta 0:00:01\n",
                        "   ---------------------------------------- 301.8/301.8 kB 6.2 MB/s eta 0:00:00\n",
                        "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
                        "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
                        "Successfully installed joblib-1.4.2 scikit-learn-1.3.2 threadpoolctl-3.5.0\n",
                        "Requirement already satisfied: torch in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (2.3.1)\n",
                        "Requirement already satisfied: filelock in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (3.13.1)\n",
                        "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (4.11.0)\n",
                        "Requirement already satisfied: sympy in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (1.12)\n",
                        "Requirement already satisfied: networkx in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (3.1)\n",
                        "Requirement already satisfied: jinja2 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (3.1.4)\n",
                        "Requirement already satisfied: fsspec in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (2024.6.0)\n",
                        "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from torch) (2021.4.0)\n",
                        "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
                        "Requirement already satisfied: tbb==2021.* in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
                        "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
                        "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
                        "Collecting transformers\n",
                        "  Using cached transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
                        "Requirement already satisfied: filelock in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from transformers) (3.13.1)\n",
                        "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
                        "  Downloading huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
                        "Requirement already satisfied: numpy>=1.17 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from transformers) (1.24.3)\n",
                        "Requirement already satisfied: packaging>=20.0 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from transformers) (24.1)\n",
                        "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from transformers) (6.0.1)\n",
                        "Collecting regex!=2019.12.17 (from transformers)\n",
                        "  Downloading regex-2024.5.15-cp38-cp38-win_amd64.whl.metadata (41 kB)\n",
                        "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
                        "     --------------------------- ---------- 30.7/42.0 kB 445.2 kB/s eta 0:00:01\n",
                        "     -------------------------------------- 42.0/42.0 kB 341.2 kB/s eta 0:00:00\n",
                        "Requirement already satisfied: requests in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from transformers) (2.32.2)\n",
                        "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
                        "  Downloading tokenizers-0.19.1-cp38-none-win_amd64.whl.metadata (6.9 kB)\n",
                        "Collecting safetensors>=0.4.1 (from transformers)\n",
                        "  Downloading safetensors-0.4.3-cp38-none-win_amd64.whl.metadata (3.9 kB)\n",
                        "Requirement already satisfied: tqdm>=4.27 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from transformers) (4.66.4)\n",
                        "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.6.0)\n",
                        "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
                        "Requirement already satisfied: colorama in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
                        "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests->transformers) (3.7)\n",
                        "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests->transformers) (2024.6.2)\n",
                        "Using cached transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
                        "Downloading huggingface_hub-0.23.4-py3-none-any.whl (402 kB)\n",
                        "   ---------------------------------------- 0.0/402.6 kB ? eta -:--:--\n",
                        "   ------ --------------------------------- 61.4/402.6 kB 3.4 MB/s eta 0:00:01\n",
                        "   ------- -------------------------------- 71.7/402.6 kB 2.0 MB/s eta 0:00:01\n",
                        "   -------------- ------------------------- 143.4/402.6 kB 1.2 MB/s eta 0:00:01\n",
                        "   -------------------- ------------------- 204.8/402.6 kB 1.4 MB/s eta 0:00:01\n",
                        "   ------------------------- -------------- 256.0/402.6 kB 1.1 MB/s eta 0:00:01\n",
                        "   ---------------------------------------- 402.6/402.6 kB 1.6 MB/s eta 0:00:00\n",
                        "Downloading regex-2024.5.15-cp38-cp38-win_amd64.whl (268 kB)\n",
                        "   ---------------------------------------- 0.0/269.0 kB ? eta -:--:--\n",
                        "   ---------------------------------------- 269.0/269.0 kB 8.3 MB/s eta 0:00:00\n",
                        "Downloading safetensors-0.4.3-cp38-none-win_amd64.whl (286 kB)\n",
                        "   ---------------------------------------- 0.0/286.9 kB ? eta -:--:--\n",
                        "   ---------------------------------------- 286.9/286.9 kB 8.6 MB/s eta 0:00:00\n",
                        "Downloading tokenizers-0.19.1-cp38-none-win_amd64.whl (2.2 MB)\n",
                        "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
                        "   --------- ------------------------------ 0.5/2.2 MB 10.5 MB/s eta 0:00:01\n",
                        "   --------- ------------------------------ 0.5/2.2 MB 10.9 MB/s eta 0:00:01\n",
                        "   ---------------- ----------------------- 0.9/2.2 MB 6.2 MB/s eta 0:00:01\n",
                        "   --------------------- ------------------ 1.2/2.2 MB 7.7 MB/s eta 0:00:01\n",
                        "   --------------------- ------------------ 1.2/2.2 MB 7.7 MB/s eta 0:00:01\n",
                        "   --------------------------- ------------ 1.5/2.2 MB 5.4 MB/s eta 0:00:01\n",
                        "   ----------------------------------- ---- 2.0/2.2 MB 6.3 MB/s eta 0:00:01\n",
                        "   ---------------------------------------- 2.2/2.2 MB 6.2 MB/s eta 0:00:00\n",
                        "Installing collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
                        "Successfully installed huggingface-hub-0.23.4 regex-2024.5.15 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.41.2\n"
                    ]
                }
            ],
            "source": [
                "!pip install openpyxl\n",
                "!pip install pandas\n",
                "!pip install pillow\n",
                "!pip install pytorch-ignite\n",
                "!pip install scikit-learn\n",
                "!pip install torch\n",
                "!pip install transformers"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Import Required Modules"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import random\n",
                "import torch\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import torch.nn as nn\n",
                "\n",
                "from ignite.metrics import Rouge\n",
                "from pandas.core.common import random_state\n",
                "from PIL import Image\n",
                "from torch.optim import AdamW\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from tqdm import tqdm\n",
                "from transformers import VisionEncoderDecoderModel, AutoTokenizer, AutoModel\n",
                "from typing import Any, Dict, List"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Set The Random Seed"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "seed = 48763\n",
                "\n",
                "np.random.seed(seed=seed, )\n",
                "\n",
                "random_state(state=seed, )\n",
                "\n",
                "random.seed(a=seed, )\n",
                "\n",
                "torch.manual_seed(seed=seed, )\n",
                "torch.cuda.manual_seed(seed=seed, )\n",
                "torch.cuda.manual_seed_all(seed=seed, )\n",
                "torch.backends.cudnn.benchmark = False\n",
                "torch.backends.cudnn.deterministic = True"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Set The Device & Initialize Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
                        "  warnings.warn(\n",
                        "Some weights of ViTModel were not initialized from the model checkpoint at nickmuchi/vit-finetuned-chest-xray-pneumonia and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
                        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
                        "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['h.0.crossattention.c_attn.bias', 'h.0.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.ln_cross_attn.bias', 'h.0.ln_cross_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.1.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.weight', 'h.1.crossattention.q_attn.bias', 'h.1.crossattention.q_attn.weight', 'h.1.ln_cross_attn.bias', 'h.1.ln_cross_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.10.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.10.ln_cross_attn.bias', 'h.10.ln_cross_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.11.crossattention.c_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.11.crossattention.c_proj.weight', 'h.11.crossattention.q_attn.bias', 'h.11.crossattention.q_attn.weight', 'h.11.ln_cross_attn.bias', 'h.11.ln_cross_attn.weight', 'h.2.crossattention.c_attn.bias', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.bias', 'h.2.crossattention.q_attn.weight', 'h.2.ln_cross_attn.bias', 'h.2.ln_cross_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.3.ln_cross_attn.bias', 'h.3.ln_cross_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.4.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.4.ln_cross_attn.bias', 'h.4.ln_cross_attn.weight', 'h.5.crossattention.c_attn.bias', 'h.5.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.5.ln_cross_attn.bias', 'h.5.ln_cross_attn.weight', 'h.6.crossattention.c_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.6.ln_cross_attn.bias', 'h.6.ln_cross_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.7.crossattention.c_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.7.ln_cross_attn.bias', 'h.7.ln_cross_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.8.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.8.ln_cross_attn.bias', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_attn.bias', 'h.9.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.9.crossattention.q_attn.bias', 'h.9.crossattention.q_attn.weight', 'h.9.ln_cross_attn.bias', 'h.9.ln_cross_attn.weight']\n",
                        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "['<|endoftext|>']\n"
                    ]
                }
            ],
            "source": [
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "\n",
                "model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(\"keremberke/yolov8m-chest-xray-classification\", \"medicalai/ClinicalBERT\").to(device)\n",
                "\n",
                "tokenizer = AutoTokenizer.from_pretrained(\"medicalai/ClinicalBERT\")\n",
                "\n",
                "print(tokenizer.all_special_tokens)\n",
                "\n",
                "tokenizer.add_special_tokens({\n",
                "    \"bos_token\": \"<|beginoftext|>\",\n",
                "    \"pad_token\": \"<|pad|>\",\n",
                "})\n",
                "\n",
                "model.config.decoder_start_token_id = tokenizer.bos_token_id\n",
                "model.config.pad_token_id = tokenizer.pad_token_id\n",
                "\n",
                "model.decoder.resize_token_embeddings(len(tokenizer))\n",
                "\n",
                "processor = .from_pretrained(\"keremberke/yolov8m-chest-xray-classification\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## The CXIRG Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CXIRGDataset(Dataset):\n",
                "    def __init__(self, data: List[Dict[str, Any]]) -> None:\n",
                "        super(CXIRGDataset, self).__init__()\n",
                "        self.data = data\n",
                "\n",
                "    def __getitem__(self, index: int) -> Dict[str, Any]:\n",
                "        return self.data[index]\n",
                "\n",
                "    def __len__(self) -> int:\n",
                "        return len(self.data)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## The Collate Function for The DataLoader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "max_length = 256\n",
                "\n",
                "def train_dl_collate_fn(one_batch_data: List[Dict[str, Any]]):\n",
                "    names = [one_data[\"name\"] for one_data in one_batch_data]\n",
                "\n",
                "    pixel_values = processor(\n",
                "        images=[one_data[\"image\"] for one_data in one_batch_data], \n",
                "        return_tensors=\"pt\"\n",
                "    ).pixel_values\n",
                "\n",
                "    label_ids = tokenizer.batch_encode_plus(\n",
                "        batch_text_or_text_pairs=[\n",
                "            (tokenizer.bos_token + one_data[\"text\"] + tokenizer.eos_token) for one_data in one_batch_data\n",
                "        ],\n",
                "        max_length=max_length,\n",
                "        padding=\"max_length\",\n",
                "        truncation=True,\n",
                "        return_tensors=\"pt\"\n",
                "    ).input_ids\n",
                "\n",
                "    return names, pixel_values.to(device), label_ids.to(device)\n",
                "\n",
                "def valid_dl_collate_fn(one_batch_data: List[Dict[str, Any]]):\n",
                "    names = [one_data[\"name\"] for one_data in one_batch_data]\n",
                "\n",
                "    pixel_values = processor(\n",
                "        images=[one_data[\"image\"] for one_data in one_batch_data], \n",
                "        return_tensors=\"pt\"\n",
                "    ).pixel_values\n",
                "\n",
                "    label_ids = tokenizer.batch_encode_plus(\n",
                "        batch_text_or_text_pairs=[\n",
                "            (tokenizer.bos_token + one_data[\"text\"] + tokenizer.eos_token) for one_data in one_batch_data\n",
                "        ],\n",
                "        max_length=max_length,\n",
                "        padding=\"max_length\",\n",
                "        truncation=True,\n",
                "        return_tensors=\"pt\"\n",
                "    ).input_ids\n",
                "\n",
                "    return names, pixel_values.to(device), label_ids.to(device)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load The Train & Validation Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_data = []\n",
                "\n",
                "report_path = \"CXIRG_Data/train_data/reports.xlsx\"\n",
                "report_df = pd.read_excel(report_path)\n",
                "\n",
                "image_dir_path = \"CXIRG_Data/train_data/images\"\n",
                "for image_name in os.listdir(image_dir_path):\n",
                "    image = Image.open(os.path.join(image_dir_path, image_name))\n",
                "    if image.mode != \"RGB\":\n",
                "        image = image.convert(\"RGB\")\n",
                "\n",
                "    text = report_df[report_df[\"name\"] == image_name[:13]][\"text\"].values[0].replace(\"_x000D_\", \"\\r\")\n",
                "\n",
                "    train_data.append({\n",
                "        \"name\": image_name[:13],\n",
                "        \"image\": image,\n",
                "        \"text\": text\n",
                "    })\n",
                "\n",
                "train_dataset = CXIRGDataset(train_data)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "valid_data = []\n",
                "\n",
                "report_path = \"CXIRG_Data/valid_data/reports.xlsx\"\n",
                "report_df = pd.read_excel(report_path)\n",
                "\n",
                "image_dir_path = \"CXIRG_Data/valid_data/images\"\n",
                "for image_name in os.listdir(image_dir_path):\n",
                "    image = Image.open(os.path.join(image_dir_path, image_name))\n",
                "    if image.mode != \"RGB\":\n",
                "        image = image.convert(\"RGB\")\n",
                "\n",
                "    text = report_df[report_df[\"name\"] == image_name[:13]][\"text\"].values[0].replace(\"_x000D_\", \"\\r\")\n",
                "\n",
                "    valid_data.append({\n",
                "        \"name\": image_name[:13],\n",
                "        \"image\": image,\n",
                "        \"text\": text\n",
                "    })\n",
                "\n",
                "valid_dataset = CXIRGDataset(valid_data)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Set The Hyperparameters & Initialize The Optimizer, Dataloaders and Evaluation Metric"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "lr = 1e-5\n",
                "epochs = 30\n",
                "optimizer = AdamW(params=model.parameters(), lr=lr)\n",
                "\n",
                "train_batch_size = 1\n",
                "valid_batch_size = 1\n",
                "train_dataloader = DataLoader(\n",
                "    dataset=train_dataset,\n",
                "    batch_size=train_batch_size,\n",
                "    shuffle=True,\n",
                "    collate_fn=train_dl_collate_fn\n",
                ")\n",
                "valid_dataloader = DataLoader(\n",
                "    dataset=valid_dataset,\n",
                "    batch_size=valid_batch_size,\n",
                "    shuffle=False,\n",
                "    collate_fn=valid_dl_collate_fn\n",
                ")\n",
                "\n",
                "rouge = Rouge(variants=[\"L\", 2], multiref=\"best\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## The Evaluation Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate(model: VisionEncoderDecoderModel, epoch: int) -> Dict[str, float]:\n",
                "    model.eval()\n",
                "\n",
                "    pbar = tqdm(valid_dataloader)\n",
                "    pbar.set_description(f\"Evaluting Epoch: {epoch + 1}\")\n",
                "\n",
                "    with torch.no_grad():\n",
                "        for names, pixel_values, label_ids in pbar:\n",
                "            predictions = model.generate(pixel_values)\n",
                "\n",
                "            _predictions = tokenizer.batch_decode(\n",
                "                predictions,\n",
                "                skip_special_tokens=True\n",
                "            )\n",
                "\n",
                "            _labels = tokenizer.batch_decode(\n",
                "                label_ids,\n",
                "                skip_special_tokens=True\n",
                "            )\n",
                "\n",
                "            print(f\"Names      : {names}\")\n",
                "            print(f\"Predictions: {_predictions}\")\n",
                "            print(f\"Labels     : {_labels}\")\n",
                "            print()\n",
                "\n",
                "            for _prediction, _label in zip(_predictions, _labels):\n",
                "                split_prediction = _prediction.split()\n",
                "                split_label = _label.split()\n",
                "\n",
                "                rouge.update(([split_prediction], [[split_label]]))\n",
                "\n",
                "    return rouge.compute()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Training Epoch [1 / 30]:  87%|████████▋ | 77/89 [06:53<01:04,  5.37s/it, loss=6.41]\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[13], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m     average_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39marray(lost_list))\n\u001b[0;32m     22\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 23\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39maverage_loss)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average_loss \u001b[38;5;241m<\u001b[39m min_loss:\n",
                        "File \u001b[1;32mc:\\Users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\optim\\optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m             )\n\u001b[1;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
                        "File \u001b[1;32mc:\\Users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
                        "File \u001b[1;32mc:\\Users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\optim\\adamw.py:188\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    175\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    177\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    178\u001b[0m         group,\n\u001b[0;32m    179\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    185\u001b[0m         state_steps,\n\u001b[0;32m    186\u001b[0m     )\n\u001b[1;32m--> 188\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
                        "File \u001b[1;32mc:\\Users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\optim\\adamw.py:340\u001b[0m, in \u001b[0;36madamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    338\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[1;32m--> 340\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32mc:\\Users\\kartg\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\optim\\adamw.py:419\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[0;32m    416\u001b[0m param\u001b[38;5;241m.\u001b[39mmul_(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m lr \u001b[38;5;241m*\u001b[39m weight_decay)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlerp_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    420\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "min_loss = float(\"inf\")\n",
                "\n",
                "for epoch in range(epochs):\n",
                "    model.train()\n",
                "\n",
                "    pbar = tqdm(train_dataloader)\n",
                "    pbar.set_description(f\"Training Epoch [{epoch + 1} / {epochs}]\")\n",
                "\n",
                "    lost_list = []\n",
                "    average_loss = 0\n",
                "\n",
                "    for _, pixel_values, label_ids in pbar:\n",
                "        optimizer.zero_grad()\n",
                "\n",
                "        loss = model(\n",
                "            pixel_values=pixel_values,\n",
                "            labels=label_ids\n",
                "        ).loss\n",
                "\n",
                "        lost_list.append(loss.item())\n",
                "        average_loss = np.mean(np.array(lost_list))\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "\n",
                "        pbar.set_postfix(loss=average_loss)\n",
                "\n",
                "    if average_loss < min_loss:\n",
                "        min_loss = average_loss\n",
                "        torch.save(model, f\"outputs/best_checkpoint.pt\")\n",
                "\n",
                "    print(f\"Rouge-2 score on epoch {epoch}:\", evaluate(model=model, epoch=epoch))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "GAI",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
